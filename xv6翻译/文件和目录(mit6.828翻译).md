# 文件和目录

## 接口:

- 创建文件:open

- 读写文件:	`strace cat foo`可以看出来cat在做什么

  打开文件,read读取/write写入

- 读取和写入,但不按顺序,lseek函数有偏移量

- fsync立即写入,普通的可能还要缓冲一会
- 文件重命名:`mv name newname` 内部rename
- 获取文件信息stat fstat 系统调用,讲路径名/文件描述符添加到文件中
- 删除文件`unlink`
- 创建目录 `rm *`  `rm -rf *`
- 读取目录 opendir -> readdir -> closedir 
- 删除目录 rmdir
- 硬连接/软连接
  - 硬:名称指向同一个文件,都只是指向文件底层元数据的链接`stat filename` 可以查看文件的引用计数(不能创建目录的硬连接,因为有可能创建一个环)
  - 软:符号连接,第一个区别是符号链 接本身实际上是一个不同类型的文件,符号链接是文件 系统知道的第三种类型
- 创建并挂载文件系统 mkfs,mount

# 文件系统实现

## 整体组织

- 数据区域:将用于存放用户数据的磁盘区域称为数据区域(data region)
-  inode:为了存储这些信息，文 件系统通常有一个名为 inode 的结构
- 空闲列表/位图:用于记录block是空闲还是已分配,

## inode

### inode包含的信息:

每个 inode 中，是所有关于文件的信息:文件类型(例如，常规文件、目录等)、 大小、分配给它的块数、保护信息(如谁拥有该文件以及谁可以访问它)、一些时间信息(包 括文件创建、修改或上次访问的时间文件下)，以及有关其数据块驻留在磁盘上的位置的信息(如某种类型的指针)。我们将所有关于文件的信息称为元数据(metadata)。实际上，文件系统中除了纯粹的用户数据外，其他任何信息通常都称为元数据。

### 多级索引(multi-level index)方法

间接指针(indirect pointer)的特殊指针。它不是指向包含用户数据的块， 而是指向包含更多指针的块，每个指针指向用户数据

我们来看 一个例子，它有 12 个直接指针，以及一个间接块和一个双重间接块。假设块大小为 4KB，并 且指针为 4 字节，则该结构可以容纳一个刚好超过 4GB 的文件，即(12 + 1024 + 10242)× 4KB。

## 目录组织

一个目录基本上只包含一个二 元组(条目名称，inode 号)的列表

## 空闲空间管理

当我们创建一个文件时，我们必须为该文件分配一个 inode。文件系统将通过位 图搜索一个空闲的内容，并将其分配给该文件。文件系统必须将 inode 标记为已使用(用 1)， 并最终用正确的信息更新磁盘上的位图。

## 访问路径:读取和写入

### 从磁盘读取文件

读入inode,找到文件 bar 的 inode,获取关于该文件的一些基本信息(权限信息、文件大小等等)。遍历(traverse)路径名， 找到所需的 inode。所有遍历都从文件系统的根开始。因此，文件系统的第一次磁盘读取是根目录的 inode。要通过i-number找到 inode，通常在其父目录中找到文件或目录的 i-number。根没有父目录,根的 inode 号必须是“众所周知的”。在大多数 UNIX 文件系统中，根的 inode 号为 2。一旦 inode 被读入，文件系统可以在其中查找指向数据块的指针，数据块包含根目录的 内容。因此，文件系统将使用这些磁盘上的指针来读取目录，在这个例子中，寻找 foo 的条 目。通过读入一个或多个目录数据块，它将找到 foo 的条目。一旦找到，文件系统也会找到 下一个需要的 foo 的 inode 号(假定是 44)。递归遍历路径名，直到找到所需的 inode。open()的最后一步是将 bar 的 inode 读入内存。权限检查，在每个进程的打开文件表中，为此进程分 配一个文件􏰀述符，并将它返回给用户。

打开后，程序可以发出 read()系统调用，从文件中读取。第一次读取(除非 lseek()已被 调用，则在偏移量 0 处)将在文件的第一个块中读取，查阅 inode 以查找这个块的位置。它会用新的最后访问时间更新 inode。读取将进一步更新此文件􏰀述符在内存中的打开文件表，更新文件偏移量，以便下一次读取会读取第二个文件块，等等。

### 写入磁盘

- 打开文件
- 发出write调用
- 关闭文件

写入逻辑上会有五个IO:

1. 一个读取数据位图(然后更新以标记新分配的块被使用)，
2. 一个写入位图(将它的新状态存入磁盘)，
3. 再是两次读取
4. 写入 inode(用新块的位置更新)
5. 最后一次写入真正的数据块本身。

反正就是有特别多特别多IO

## 缓存和缓冲

动态划分(dynamic partitioning)



# 局部性和快速文件系统

老文件系统性能很糟糕:磁盘定位慢,空间碎片化,原始块大小太小

## FFS:(Fast File System，FFS)

### 组织结构:柱面组

更改磁盘上的结构,将磁盘划分为一些分组，称为柱面组,通过在同一组中放置两个文件，FFS 可以 确保先后访问两个文件不会导致穿越磁盘的长时间寻道。

![image-20191216151330615](/Users/dylan/Library/Application Support/typora-user-images/image-20191216151330615.png)

**超级块的一个副本**:可靠性

**inode 位图(inode bitmap)和数据位图(data bitmap)**:记录该组的 inode 和数据块是否已分配。起到了这个作用，分别针对每组中的 inode 和数据块。

### 策略:如何分配文件和目录

**相关的东西放一起**

1. 目录的放置:找到分配数量少的柱面组(因为我们希望跨组平衡目录)和大量的自由 inode(因为我们希望随后能够分配一堆文件)，并将目录数据 和 inode 放在该分组中

2. 文件，FFS 做两件事。首先，它确保(在一般情况下)将文件的数据块分配到与其 inode 相同的组中，从而防止 inode 和数据之间的长时间寻道(如在老文件系统中)。其次， 它将位于同一目录中的所有文件，放在它们所在目录的柱面组中。

> **大文件例外**
>
> 大文件将填满它首先放入的块组(也可能填满其他组),妨碍了随后的“相关”文件放置在该块组内，因此可能破坏文件访 问的局部性。
>
> FFS 将文件的下一个“大”块(即第一 个间接块指向的那些部分)放在另一个块组中
>
> **小文件**
>
> 引入子块(sub-block)， 这些子块有 512 字节，文件系统可以将它们分配给文件。
>
> **允许长文件名**
>
> **是针对性能进行优化的磁盘布局**



# 崩溃一致性:FSCK和日志

崩溃一致性问题(crash-consistency problem):

如果在更新磁盘结构的过程中，有人绊到电源线并且机器断电，会发生什么?或者操作系统遇到错误并崩溃?由于断电和崩溃， 更新持久性数据结构可能非常棘手

## 崩溃场景

## 解决方案 

### 1:文件系统检查程序

以下是 fsck 的基本总结(反正就是依次检查一遍看有啥毛病没反正现在不怎么用)

```
- 􏰂  超级块:fsck 首先检查超级块是否合理，主要是进行健全性检查，例如确保文件系

  统大小大于分配的块数。通常，这些健全性检查的目的是找到一个可疑的冲突

- 􏰂空闲块:接下来，fsck 扫􏰀 inode、间接块、双重间接块等，以了解当前在文件系 统中分配的块。它利用这些知识生成正确版本的分配位图。因此，如果位图和 inode 之间存在任何不一致，则通过信任 inode 内的信息来解决它。对所有 inode 执行相同类型的检查，确保所有看起来像在用的 inode，都在 inode 位图中有标记。

- 􏰂inode 状态:检查每个 inode 是否存在损坏或其他问题。例如，fsck 确保每个分配 的 inode 具有有效的类型字段(即常规文件、目录、符号链接等)。如果 inode 字 段存在问题，不易修复，则 inode 被认为是可疑的，并被 fsck 清除，inode 位图相应地更新。

- 􏰂inode 链接:fsck 还会验证每个已分配的 inode 的链接数。你可能还记得，链接计

  数表示包含此特定文件的引用(即链接)的不同目录的数量。为了验证链接计数， fsck 从根目录开始扫􏰀整个目录树，并为文件系统中的每个文件和目录构建自己的􏰂

- 链接计数。如果新计算的计数与 inode 中找到的计数不匹配，则必须采取纠正措施， 通常是修复 inode 中的计数。如果发现已分配的 inode 但没有目录引用它，则会将 其移动到 lost + found 目录。
   重复:fsck 还检查重复指针，即两个不同的 inode 引用同一个块的情况。如果一个 inode 明显不好，可能会被清除。或者，可以复制指向的块，从而根据需要为每个 inode 􏰁供其自己的副本。

- 􏰂 坏块:在扫􏰀所有指针列表时，还会检查坏块指针。如果指针显然指向超出其有 效范围的某个指针，则该指针被认为是“坏的”，例如，它的地址指向大于分区 大小的块。在这种情况下，fsck 不能做任何太聪明的事情。它只是从 inode 或间接 块中删除(清除)该指针。

- 目录检查:fsck 不了解用户文件的内容。但是，目录包含由文件系统本身创建的特 定格式的信息。因此，fsck 对每个目录的内容执行额外的完整性检查，确保“.” 和“..”是前面的条目，目录条目中引用的每个 inode 都已分配，并确保整个层次 结构中没有目录的引用超过一次。
```

### 2:日志

![image-20191216153344391](/Users/dylan/Library/Application Support/typora-user-images/image-20191216153344391.png)

#### 

#### 数据日志

希望将 inode(I[v2])、位图(B[v2])和数据块 (Db)写入磁盘。在将它们写入最终磁盘位置之前，现在先将它们写入日志。这就是日志中的样子:

![image-20191216154247213](/Users/dylan/Library/Application Support/typora-user-images/image-20191216154247213.png)

初始:

1. 日志写入:将事务(包括事务开始块，所有即将写入的数据和元数据更新以及事务 结束块)写入日志

2. 加检查点:将待处理的元数据和数据更新写入文件系统中的最终位置。

后来:

1.日志写入:将事务的内容(包括 TxB、元数据和数据)写入日志，等待这些写入完成。

2.日志提交:将事务提􏰁交块(包括 TxE)写入日志，等待写完成，事务被认为已􏰁交 (committed)。

3.加检查点:将更新内容(元数据和数据)写入其最终的磁盘位置。

变化就是只有在TxE之前的所有内容都完成了之后才把TxE写进去

#### 恢复

如果崩溃发生在事务被安全地写入日志之前(在上面的步骤 2 完成之前)，简单地跳过待执行的更新。

如果在事务已􏰁交到日志之后但在加检查点完成之前发生崩溃,就把做了一半的事重新做一次:

> 文件系统恢复过程将扫􏰀描日志，并查找已􏰁交到磁盘的事务,这些事务被重放(replayed，按顺序)，文件系统再次尝试将事务中的块写入它们最终的磁盘位置。 这种形式的日志是最简单的形式之一，称为重做日志(redo logging)。

#### 批处理日志更新

> 假设我们在同 一目录中连续创建两个文件，必须更新许多磁盘上的 结构，至少包括:inode 位图(分配新的 inode)，新创建的文件 inode，包含新文件目录条目 的父目录的数据块，以及父目录的 inode(现在有一个新的修改时间)。因为文件在同一个目录中,如果不小心，我们最终会一遍又一遍地写入这 些相同的块。So,一些文件系统不会一次一个地向磁盘􏰁交每个更新，可以将所有更新缓冲到全局事务中。当创建两个文件 时，文件系统只将内存中的 inode 位图、文件的 inode、目录数据和目录 inode 标记为脏，并将它们添加到块列表中，形成当前的事务。当最后应该将这些块写入磁盘时，会提􏰁交包含上述所有更新的单个全局事务

缓冲更新，文件系统在许多情况下可以避免对磁盘的过多的写入流量:



# 日志结构文件系统

出现的原因:内存变大,顺序读取相对随机IO变快了好多,FFS不咋好用,文件系统不支持RAID

写入磁盘时，LFS 首先将所有更新(包括元数据)缓冲在内存段中。当段已满时，它会在一次长时间的顺序传输中写入磁盘，并传输到磁盘的未使用部分。LFS 永远不会覆写现有数据，而是始终将段写入空闲位置。由于段很大，因此可以有效地使用磁盘，并且文件系统的性能接近其峰值。

## 按顺序写入磁盘:

必须向驱动器发出大量连续写入:

> (单单)顺序写入磁盘并不足以保证高效写入。例如，假设我们在时间 T 向 地址 A 写入一个块。然后等待一会儿，再向磁盘写入地址 A+1(下一个块地址按顺序)，遗憾的是，在第一次和第二次写入之间，磁盘已经旋转。当你发出第二次写 入时，它将在􏰁交之前等待一大圈旋转,你必须向驱动器发出大量连续写入(或一次大 写入)才能获得良好的写入性能。

写入缓冲:在 写入磁盘之前，LFS 会跟踪内存中的更新。收到足够数量的更新时，会立即将它们写入磁盘， 从而确保有效使用磁盘。LFS 一次写入的大块更新被称为段(segment)。

## 要缓冲多少

## 查找inode

### 不同版本的不同查找方式:

1. 在典型的文件系统(如 FFS)甚至老 UNIX 文件系统中:查很 inode 很容易， 因为它们以数组形式组织，并放在磁盘的固定位置上。例如，老 UNIX 文件系统将所有 inode 保存在磁盘的固定位置。因此，给定一个 inode 号和起始地址，要查很特定的 inode，只需将 inode 号乘以 inode 的大小，然后将其加上磁盘 数组的起始地址，即可计算其确切的磁盘地址。给定一个 inode 号，基于数组的索引是快速 而直接的。

2. 在 FFS 中查很给定 inode 号的 inode 仅稍微复杂一些，因为 FFS 将 inode 表拆分为块并 在每个柱面组中放置一组 inode。因此，必须知道每个 inode 块的大小和每个 inode 的起始地 址。之后的计算类似，也很容易。

3. 在 LFS 中，生活比较艰很。我们已经设法将 inode 分散在整个磁盘上! 更糟糕的是，我们永远不会覆盖，因此最新版本的 inode(即我们想要的那个)会不断移动。

### inode映射

1. inode 号和 inode 之间引入了一个间接层imap ,它将 inode 号作为输入，并生成最新版本的 inode 的磁盘地址

2. imap 需要保持持久(写入磁盘)。这样做允许 LFS 在崩溃时仍能记录 inode 位置

3. imap 应该驻留在磁盘上的哪个位置?

   不能存在于磁盘的固定部分。因为它经常更新,性能会受到影响;

   LFS 将 inode 映射的块放在它写入所有其他新信息的位置旁边。因此，当将 数据块追加到文件 k 时，LFS 实际上将新数据块，其 inode 和一段 inode 映射一起写入磁盘， 如下所示:

   ![image-20191216170122764](/Users/dylan/Library/Application Support/typora-user-images/image-20191216170122764.png)

### 检查点区域

如何找到 inode映射，现在它的各个部分现在也分布在整个磁盘上?归根到底:文件系统必须在磁盘上有一 些固定且已知的位置，才能开始文件。

检查点区域(checkpoint region，CR):LFS在磁盘上只有这样一个固定的位置。包含指向最新的 inode 映射片段的指针(即地址)，因此可以通过首先读取 CR 来很 到 inode 映射片段。请注意，检查点区域仅定期更新(例如每 30s 左右)，因此性能不会受到 影响。因此，磁盘布局的整体结构包含一个检查点区域(指向内部映射的最新部分)，每个 inode 映射块包含 inode 的地址，inode 指向文件(和目录)，就像典型的 UNIX 文件系统一样。

下面的例子是检查点区域(注意它始终位于磁盘的开头，地址为 0)，以及单个 imap 块，

![image-20191216170441059](/Users/dylan/Library/Application Support/typora-user-images/image-20191216170441059.png)

### 目录的存储

目录只是(名称，inode 号)映射的集合

你先要查看 inode 映射(通常缓存在内存中)，很到目录 dir(A3) 的 inode 的位置。然后读取目录的 inode，它给你目录数据的位置(A2)

>inode 映射还解决了 LFS 中存在的另一个严重问题，称为递归更新问题(recursive update
>
>problem)[Z+12]。任何永远不会原地更新的文件系统(例如 LFS)都会遇到该问题，它们 将更新移动到磁盘上的新位置。
>
>具体来说，每当更新 inode 时，它在磁盘上的位置都会发生变化。如果我们不小心，这 也会导致对指向该文件的目录的更新，然后必须更改该目录的父目录，依此类推，一路沿 文件系统树向上。
>
>LFS 巧妙地避免了 inode 映射的这个问题。即使 inode 的位置可能会发生变化，更改也 不会反映在目录本身中。事实上，imap 结构被更新，而目录保持相同的名称到 inumber 的 映射。因此，通过间接，LFS 避免了递归更新问题。

### 一个新问题:垃圾收集

`版本控制文件系统(versioning file system)`:可以保留那些旧版本并允许用 户恢复旧文件版本(例如，当他们意外覆盖或删除文件时，这样做可能非常方便),它跟踪文件的不同版本。

LFS 只保留文件的最新活版本。

LFS 清理程序**按段工作**:定期读入许多旧的(部分使用的)段，然后写出一组新的段，只包含其中活着的块，释放旧块。

####  确定块的死活

**段摘要块(segment summary block)**:对于每个数据块 D， LFS 包括其 inode 号(它属于哪个文件)及其偏移量(这是该文件的哪一块)。该信息记录 在一个数据结构中，位于段头部，称为段摘要块(segment summary block)。

对于位于地址 A 的磁盘上的块 D，

1. 查看段摘要块找到其 inode 号 N 和偏移量 T
2. 接下来，查看 imap 以找到 N 所在的位置，并从磁盘读取 N(可能它已经在内存中，这更好)。
3. 最后，利用偏移量 T，查看 inode(或某个间接块)， 看看 inode 认为此文件的第 T 个块在磁盘上的位置。
   - 如果它刚好指向磁盘地址 A，则 LFS 可以断定块 D 是活的。
   - 如果它指向其他地方，LFS 可以断定 D 未被使用(即它已经死了)

```C
(N, T) = SegmentSummary[A];
inode = Read(imap[N]);
if (inode[T] == A)
		// block D is alive else
else 
		// block D is garbage
```

#### 策略问题:要清理哪些块，何时清理

#### 崩溃恢复和日志

在正常操作期间，LFS 将一些写入缓冲在段中，然后(当段已满或经过一段时间后)， 将段写入磁盘。LFS 在日志(log)中组织这些写入，即指向头部段和尾部段的检查点区域， 并且每个段指向要写入的下一个段。LFS 还定期更新检查点区域(CR)。在这些操作期间都 可能发生崩溃(写入段，写入 CR)。那么 LFS 在写入这些结构时如何处理崩溃?

写入CR:

为了确保 CR 更新以原子方式发生，LFS 实际上保留了两个 CR，每个位于磁盘的一端，并交替写入它们。

它首先写出一个头(带有时间戳)，然后写出 CR 的主体，然后最后写出最后一部分(也带有时间戳)。如果系统在 CR 更 新期间崩溃，LFS可以通过查看一对不一致的时间戳来检测到这一点。LFS将始终选择使用 具有一致时间戳的最新 CR，从而实现 CR 的一致更新。

写入段:

> 由于 LFS 每隔 30s 左右写入一次 CR，因此文件系统的最后一致快照可能很旧。因此，在重新启动时，LFS 可以通过简单地读取检查点区域、它指向的 imap 片段以及后续文件和目录，从而轻松地恢复。但是，最后许多秒的更新将会丢失。

> 为了改进这一点，LFS 尝试通过数据库社区中称为前滚(roll forward)的技术，重建其中许多段。基本思想是从最后一个检查点区域开始，很到日志的结尾(包含在 CR 中)，然 后使用它来读取下一个段，并查看其中是否有任何有效更新。如果有，LFS 会相应地更新文 件系统，从而恢复自上一个检查点以来写入的大部分数据和元数据。